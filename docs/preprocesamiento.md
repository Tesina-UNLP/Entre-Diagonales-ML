# Preprocesamiento de ImÃ¡genes

Este documento explica las tÃ©cnicas de preprocesamiento de imÃ¡genes utilizadas en el proyecto, con ejemplos prÃ¡cticos y justificaciones tÃ©cnicas.

## ðŸ–¼ï¸ Â¿QuÃ© es el Preprocesamiento?

El preprocesamiento es la preparaciÃ³n de datos de entrada para que el modelo pueda procesarlos de manera Ã³ptima. En visiÃ³n por computadora, esto incluye transformaciones como normalizaciÃ³n, redimensionamiento y aumentaciÃ³n de datos.

## ðŸ”§ Preprocesamiento en Nuestro Proyecto

### 1. NormalizaciÃ³n de PÃ­xeles

#### Rescaling (MÃ©todo Simple)
```python
# En EfficientNet
x = layers.Rescaling(1./255)(inputs)

# Convierte valores de [0, 255] a [0, 1]
pixel_original = 128  # Valor tÃ­pico de pixel
pixel_normalizado = 128 / 255 = 0.502
```

#### Preprocesamiento EspecÃ­fico del Modelo
```python
# MobileNet
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
x = mobilenet_preprocess(x)

# EfficientNet
from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess
x = efficientnet_preprocess(x)

# ConvNeXt
from tensorflow.keras.applications.convnext import preprocess_input as convnext_preprocess
x = convnext_preprocess(x)
```

### 2. Redimensionamiento AutomÃ¡tico

```python
# Durante la carga del dataset
train_ds = image_dataset_from_directory(
    directory="data/train",
    image_size=(224, 224),  # Redimensiona automÃ¡ticamente
    batch_size=32
)
```

#### Â¿Por quÃ© diferentes tamaÃ±os?

| Modelo | TamaÃ±o | RazÃ³n |
|--------|--------|-------|
| MobileNet | 224Ã—224 | EstÃ¡ndar, optimizado para velocidad |
| EfficientNet | 300Ã—300 | Mejor para detalles finos |
| ResNeSt | 224Ã—224 | Balance velocidad/precisiÃ³n |
| ConvNeXt | 224Ã—224 | Moderno, hÃ­brido convolutivo-transformer |

### 3. ConversiÃ³n de Formatos

```python
# En utils.py
def convert_jfif_to_jpg(path):
    """Convierte archivos .jfif a .jpg"""
    for dirpath, _, filenames in os.walk(path):
        for f in filenames:
            if f.lower().endswith(".jfif"):
                src = os.path.join(dirpath, f)
                dst = os.path.join(dirpath, Path(f).stem + ".jpg")
                try:
                    with Image.open(src) as img:
                        img.convert("RGB").save(dst, "JPEG")
                    os.remove(src)
                except Exception as e:
                    print(f"Error convirtiendo {src}: {e}")
```

**Formatos soportados:**
- JPG/JPEG âœ…
- PNG âœ…
- JFIF â†’ JPG (conversiÃ³n automÃ¡tica) âœ…
- BMP, TIFF, etc. (requieren conversiÃ³n manual) âš ï¸

## ðŸŽ¨ AumentaciÃ³n de Datos (Data Augmentation)

### ImplementaciÃ³n en MobileNet

```python
# AumentaciÃ³n integrada en el modelo
augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),    # Volteo horizontal
    layers.RandomRotation(0.1),         # RotaciÃ³n aleatoria
    layers.RandomZoom(0.1),             # Zoom aleatorio
]) if use_augmentation else tf.keras.Sequential([])

# AplicaciÃ³n en el pipeline
inputs = tf.keras.Input(shape=img_size + (3,))
x = augmentation(inputs)  # Solo durante entrenamiento
x = mobilenet_preprocess(x)
# ... resto del modelo
```

### TÃ©cnicas de AumentaciÃ³n Explicadas

#### 1. Random Flip
```python
layers.RandomFlip("horizontal")

# Ejemplo visual:
# Original:    [ðŸ¶]
# Flipped:     [ðŸ¶] (espejo horizontal)
# Probabilidad: 50%
```

**Â¿Por quÃ© funciona?**
- Los objetos pueden aparecer en cualquier orientaciÃ³n
- Duplica efectivamente el dataset
- Mejora la generalizaciÃ³n

#### 2. Random Rotation
```python
layers.RandomRotation(0.1)  # Â±10% = Â±36 grados

# Ejemplo:
# factor = 0.1 significa rotaciÃ³n entre -36Â° y +36Â°
# factor = 0.2 serÃ­a entre -72Â° y +72Â°
```

**Casos de uso:**
- âœ… Objetos naturales (animales, plantas)
- âœ… FotografÃ­as casuales
- âŒ Texto (se volverÃ­a ilegible)
- âŒ Objetos con orientaciÃ³n fija

#### 3. Random Zoom
```python
layers.RandomZoom(0.1)  # Zoom entre 90% y 110%

# height_factor y width_factor = [-0.1, 0.1]
# zoom_out: 0.9x (imagen mÃ¡s pequeÃ±a, padding)
# zoom_in: 1.1x (imagen mÃ¡s grande, recorte)
```

### AumentaciÃ³n Avanzada (Opcional)

```python
# Aumentaciones adicionales que podrÃ­as agregar
advanced_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomRotation(0.1),
    layers.RandomZoom(0.1),
    layers.RandomBrightness(0.1),      # Brillo Â±10%
    layers.RandomContrast(0.1),        # Contraste Â±10%
    # layers.RandomTranslation(0.1, 0.1), # TraslaciÃ³n (TF 2.6+)
])
```

#### Ejemplo de ImplementaciÃ³n:
```python
def create_augmented_model(base_model, img_size, num_classes, augment_strength="medium"):
    """Crea modelo con diferentes niveles de aumentaciÃ³n"""
    
    augmentation_configs = {
        "light": {
            "flip": True,
            "rotation": 0.05,  # Â±18Â°
            "zoom": 0.05,      # Â±5%
            "brightness": 0.0,
            "contrast": 0.0
        },
        "medium": {
            "flip": True,
            "rotation": 0.1,   # Â±36Â°
            "zoom": 0.1,       # Â±10%
            "brightness": 0.1,
            "contrast": 0.05
        },
        "heavy": {
            "flip": True,
            "rotation": 0.2,   # Â±72Â°
            "zoom": 0.2,       # Â±20%
            "brightness": 0.2,
            "contrast": 0.1
        }
    }
    
    config = augmentation_configs[augment_strength]
    
    augmentation_layers = []
    if config["flip"]:
        augmentation_layers.append(layers.RandomFlip("horizontal"))
    if config["rotation"] > 0:
        augmentation_layers.append(layers.RandomRotation(config["rotation"]))
    if config["zoom"] > 0:
        augmentation_layers.append(layers.RandomZoom(config["zoom"]))
    if config["brightness"] > 0:
        augmentation_layers.append(layers.RandomBrightness(config["brightness"]))
    if config["contrast"] > 0:
        augmentation_layers.append(layers.RandomContrast(config["contrast"]))
    
    augmentation = tf.keras.Sequential(augmentation_layers)
    
    # Construir modelo
    inputs = tf.keras.Input(shape=img_size + (3,))
    x = augmentation(inputs)
    x = base_model(x, training=False)
    # ... resto de capas
    
    return model
```

## ðŸ“Š Pipeline de Datos Optimizado

### ImplementaciÃ³n Actual
```python
def create_datasets(temp_dir, img_size, batch_size, seed):
    """Crea datasets optimizados"""
    
    # Cargar datasets
    train_ds_raw = image_dataset_from_directory(
        f"{temp_dir}/train", 
        seed=seed, 
        image_size=img_size, 
        batch_size=batch_size
    )
    
    val_ds_raw = image_dataset_from_directory(
        f"{temp_dir}/test", 
        seed=seed, 
        image_size=img_size, 
        batch_size=batch_size
    )
    
    # OptimizaciÃ³n de performance
    AUTOTUNE = tf.data.AUTOTUNE
    train_ds = train_ds_raw.prefetch(AUTOTUNE)
    val_ds = val_ds_raw.prefetch(AUTOTUNE)
    
    return train_ds, val_ds, class_names, num_classes
```

### Pipeline Optimizado Avanzado
```python
def create_optimized_pipeline(data_dir, img_size, batch_size, augment=True):
    """Pipeline de datos con optimizaciones avanzadas"""
    
    # FunciÃ³n de preprocesamiento
    def preprocess_image(image, label):
        # Normalizar a [0, 1]
        image = tf.cast(image, tf.float32) / 255.0
        return image, label
    
    # FunciÃ³n de aumentaciÃ³n (solo para entrenamiento)
    def augment_image(image, label):
        image = tf.image.random_flip_left_right(image)
        image = tf.image.random_brightness(image, 0.1)
        image = tf.image.random_contrast(image, 0.9, 1.1)
        return image, label
    
    # Cargar dataset
    train_ds = tf.keras.preprocessing.image_dataset_from_directory(
        f"{data_dir}/train",
        image_size=img_size,
        batch_size=batch_size,
        shuffle=True
    )
    
    val_ds = tf.keras.preprocessing.image_dataset_from_directory(
        f"{data_dir}/test",
        image_size=img_size,
        batch_size=batch_size,
        shuffle=False
    )
    
    # Aplicar transformaciones
    train_ds = train_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    if augment:
        train_ds = train_ds.map(augment_image, num_parallel_calls=tf.data.AUTOTUNE)
    
    val_ds = val_ds.map(preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)
    
    # Optimizaciones de performance
    train_ds = train_ds.cache().prefetch(tf.data.AUTOTUNE)
    val_ds = val_ds.cache().prefetch(tf.data.AUTOTUNE)
    
    return train_ds, val_ds
```

## ðŸ” AnÃ¡lisis de Preprocesamiento

### Verificar NormalizaciÃ³n
```python
def analyze_dataset_stats(dataset):
    """Analiza estadÃ­sticas del dataset"""
    
    pixel_values = []
    
    for images, labels in dataset.take(5):  # Tomar 5 batches
        pixel_values.extend(images.numpy().flatten())
    
    pixel_values = np.array(pixel_values)
    
    print(f"Min pixel value: {pixel_values.min():.4f}")
    print(f"Max pixel value: {pixel_values.max():.4f}")
    print(f"Mean pixel value: {pixel_values.mean():.4f}")
    print(f"Std pixel value: {pixel_values.std():.4f}")
    
    # Verificar rango esperado
    if pixel_values.min() >= 0 and pixel_values.max() <= 1:
        print("âœ… NormalizaciÃ³n correcta [0, 1]")
    elif pixel_values.min() >= -1 and pixel_values.max() <= 1:
        print("âœ… NormalizaciÃ³n correcta [-1, 1]")
    else:
        print("âš ï¸ Verificar normalizaciÃ³n")

# Uso
analyze_dataset_stats(train_ds)
```

### Visualizar AumentaciÃ³n
```python
def visualize_augmentation(dataset, class_names):
    """Visualiza el efecto de la aumentaciÃ³n"""
    
    plt.figure(figsize=(15, 10))
    
    for images, labels in dataset.take(1):
        for i in range(min(8, len(images))):
            # Imagen original (sin aumentaciÃ³n)
            plt.subplot(2, 4, i + 1)
            plt.imshow(images[i])
            plt.title(f"Original: {class_names[labels[i]]}")
            plt.axis('off')
            
            # Si tuviÃ©ramos aumentaciÃ³n aplicada, la mostrarÃ­amos aquÃ­
    
    plt.tight_layout()
    plt.show()

# Para ver aumentaciÃ³n en tiempo real
def show_augmentation_effects():
    """Muestra efectos de aumentaciÃ³n en tiempo real"""
    
    # Cargar una imagen de ejemplo
    img_path = "data/clase1/train/ejemplo.jpg"
    img = tf.keras.preprocessing.image.load_img(img_path, target_size=(224, 224))
    img_array = tf.keras.preprocessing.image.img_to_array(img)
    img_array = tf.expand_dims(img_array, 0) / 255.0
    
    # Crear aumentaciÃ³n
    augmentation = tf.keras.Sequential([
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.1),
    ])
    
    # Mostrar mÃºltiples versiones aumentadas
    plt.figure(figsize=(15, 3))
    
    # Original
    plt.subplot(1, 6, 1)
    plt.imshow(img_array[0])
    plt.title("Original")
    plt.axis('off')
    
    # 5 versiones aumentadas
    for i in range(5):
        augmented = augmentation(img_array, training=True)
        plt.subplot(1, 6, i + 2)
        plt.imshow(augmented[0])
        plt.title(f"Aumentada {i+1}")
        plt.axis('off')
    
    plt.tight_layout()
    plt.show()
```

## ðŸ’¡ Mejores PrÃ¡cticas

### 1. CuÃ¡ndo Usar Cada AumentaciÃ³n

```python
augmentation_guidelines = {
    "fotografÃ­as_naturales": {
        "flip": True,          # Animales, paisajes
        "rotation": 0.1,       # Objetos en cualquier orientaciÃ³n
        "zoom": 0.1,          # Diferentes distancias
        "brightness": 0.1      # Diferentes condiciones de luz
    },
    
    "documentos_texto": {
        "flip": False,         # Texto no se voltea
        "rotation": 0.02,      # MÃ­nima rotaciÃ³n (documentos escaneados)
        "zoom": 0.05,         # Poco zoom
        "brightness": 0.05     # MÃ­nimo cambio de brillo
    },
    
    "imagenes_medicas": {
        "flip": True,          # AnatomÃ­a puede aparecer en espejo
        "rotation": 0.05,      # Poca rotaciÃ³n (mantener orientaciÃ³n mÃ©dica)
        "zoom": 0.05,         # Poco zoom (no perder detalles)
        "brightness": 0.02     # MÃ­nimo (importante para diagnÃ³stico)
    },
    
    "objetos_manufacturados": {
        "flip": True,          # Productos pueden aparecer en espejo
        "rotation": 0.1,       # Diferentes Ã¡ngulos de vista
        "zoom": 0.15,         # Diferentes distancias de cÃ¡mara
        "brightness": 0.1      # Diferentes condiciones de iluminaciÃ³n
    }
}
```

### 2. Evitar AumentaciÃ³n Excesiva

```python
# âŒ AumentaciÃ³n excesiva
bad_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),
    layers.RandomFlip("vertical"),        # Raramente Ãºtil
    layers.RandomRotation(0.5),          # Â±180Â° demasiado
    layers.RandomZoom(0.5),              # Â±50% muy extremo
    layers.RandomBrightness(0.5),        # Cambios muy drÃ¡sticos
    layers.RandomContrast(0.5),
])

# âœ… AumentaciÃ³n balanceada
good_augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),      # 50% probabilidad
    layers.RandomRotation(0.1),          # Â±36Â° razonable
    layers.RandomZoom(0.1),              # Â±10% moderado
    layers.RandomBrightness(0.1),        # Â±10% sutil
])
```

### 3. Monitoreo del Preprocesamiento

```python
def validate_preprocessing_pipeline(dataset, expected_range=(0, 1)):
    """Valida que el preprocesamiento sea correcto"""
    
    checks = {
        "range_check": False,
        "shape_check": False,
        "type_check": False,
        "nan_check": False
    }
    
    for images, labels in dataset.take(1):
        # Verificar rango de valores
        min_val, max_val = tf.reduce_min(images), tf.reduce_max(images)
        if min_val >= expected_range[0] and max_val <= expected_range[1]:
            checks["range_check"] = True
        
        # Verificar forma
        if len(images.shape) == 4:  # (batch, height, width, channels)
            checks["shape_check"] = True
        
        # Verificar tipo
        if images.dtype == tf.float32:
            checks["type_check"] = True
        
        # Verificar NaN
        if not tf.reduce_any(tf.math.is_nan(images)):
            checks["nan_check"] = True
        
        break
    
    # Imprimir resultados
    for check, passed in checks.items():
        status = "âœ…" if passed else "âŒ"
        print(f"{status} {check}: {passed}")
    
    return all(checks.values())

# Usar despuÃ©s de crear el dataset
is_valid = validate_preprocessing_pipeline(train_ds)
if is_valid:
    print("ðŸŽ‰ Pipeline de preprocesamiento vÃ¡lido!")
else:
    print("âš ï¸ Revisar pipeline de preprocesamiento")
```
