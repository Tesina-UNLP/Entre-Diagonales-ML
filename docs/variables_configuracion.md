# Variables y Configuraciones del Proyecto

Este documento explica todas las variables importantes, configuraciones y par√°metros utilizados en el proyecto de clasificaci√≥n de im√°genes.

## ‚öôÔ∏è Variables de Configuraci√≥n Global

### Archivo: `config.py`

#### Rutas y Directorios
```python
# Directorio ra√≠z donde se encuentran los datos organizados por clases
DATA_ROOT = "data"

# Directorio temporal para reorganizar datos durante entrenamiento
TEMP_DIR = "temp_dataset"

# Directorio base donde se guardan los modelos entrenados
MODEL_DIR_BASE = "models"

# Directorio para guardar gr√°ficas y visualizaciones
PLOT_DIR = "plots"
```

**Explicaci√≥n pr√°ctica:**
- `DATA_ROOT`: Aqu√≠ van tus carpetas de clases (ej: data/perros/, data/gatos/)
- `TEMP_DIR`: Se crea autom√°ticamente durante entrenamiento y se borra despu√©s
- `MODEL_DIR_BASE`: Cada modelo entrenado crea una subcarpeta con timestamp
- `PLOT_DIR`: Guarda las curvas de accuracy, loss y matriz de confusi√≥n

#### Configuraciones Espec√≠ficas por Modelo
```python
MODEL_SPECIFIC_CONFIG = {
    "mobilenet": {
        "img_size": (244, 244),      # Resoluci√≥n de entrada
        "learning_rate": 0.001,      # Tasa de aprendizaje
        "dropout_rate": 0.2,         # Porcentaje de dropout
        "use_augementation": True,   # Usar aumentaci√≥n de datos
        "dense_units": 64,           # Neuronas en capa densa
    },
    "efficientnet": {
        "img_size": (300, 300),
        "learning_rate": 0.0001,     # M√°s conservador
        "dropout_rate": 0.3,         # M√°s regularizaci√≥n
    },
    "resnest": {
        "img_size": (224, 224),
        "learning_rate": 0.001,
        "dropout_rate": 0.3,
        "dense_units": 250,          # M√°s neuronas
    },
    "convnext": {
        "img_size": (224, 224),
        "learning_rate": 0.0001,     # Conservador para modelo moderno
        "dropout_rate": 0.3,         # Regularizaci√≥n est√°ndar
        "dense_units": 128,          # Balance para arquitectura h√≠brida
    }
}
```

## üß† Variables de Modelo

### Archivo: `models.py`

#### Configuraci√≥n de Modelos
```python
MODEL_CONFIGS = {
    "efficientnet": {
        "img_size": (300, 300),           # Tama√±o de imagen de entrada
        "batch_size": 32,                 # Im√°genes por lote
        "epochs": 15,                     # √âpocas de entrenamiento
        "create_fn": create_efficientnet_model,  # Funci√≥n constructora
        "description": "Modelo EfficientNetB3 con preprocesamiento...",
    },
    # ... otros modelos
}
```

#### Par√°metros de Arquitectura

**Input Shape (Forma de Entrada)**
```python
input_shape = img_size + (3,)  # (altura, ancho, canales RGB)

# Ejemplos:
# MobileNet: (224, 224, 3)
# EfficientNet: (300, 300, 3)
# ResNeSt: (224, 224, 3)
# ConvNeXt: (224, 224, 3)
```

**¬øPor qu√© diferentes tama√±os?**
- **224x224**: Est√°ndar hist√≥rico, balance velocidad/calidad
- **300x300**: Mejor para detalles finos, usado en EfficientNet
- **512x512+**: Para im√°genes m√©dicas o sat√©lites (no usado aqu√≠)

**Dropout Rate**
```python
dropout_rate = 0.3  # 30% de neuronas se "apagan" aleatoriamente

# Efectos:
# 0.0: Sin regularizaci√≥n, riesgo de overfitting
# 0.2-0.3: Balance recomendado
# 0.5+: Mucha regularizaci√≥n, puede underfitting
```

**Learning Rate (Tasa de Aprendizaje)**
```python
learning_rates = {
    "alto": 0.01,      # Aprendizaje r√°pido, inestable
    "medio": 0.001,    # Balance recomendado
    "bajo": 0.0001,    # Conservador, convergencia lenta
}
```

## üéØ Variables de Entrenamiento

### Archivo: `train.py`

#### Configuraci√≥n Global de Entrenamiento
```python
CONFIG = {
    "data_root": "data",          # Directorio de datos
    "temp_dir": "temp_dataset",   # Directorio temporal
    "model_dir_base": "models",   # Modelos entrenados
    "plot_dir": "plots",          # Gr√°ficas
    "seed": 42                    # Semilla para reproducibilidad
}
```

#### Par√°metros del Dataset
```python
# En la funci√≥n create_datasets()
train_ds = image_dataset_from_directory(
    directory=f"{temp_dir}/train",
    seed=42,                    # Reproducibilidad
    image_size=img_size,        # Redimensionar autom√°ticamente
    batch_size=batch_size,      # Im√°genes por lote
    validation_split=None       # Sin split adicional (ya dividido)
)
```

#### Variables de Optimizaci√≥n
```python
AUTOTUNE = tf.data.AUTOTUNE    # Optimizaci√≥n autom√°tica de pipeline

# Aplicado como:
train_ds = train_ds.prefetch(AUTOTUNE)  # Cargar datos en paralelo
```

## üìä Variables de Evaluaci√≥n

### Archivo: `utils.py`

#### M√©tricas de Clasificaci√≥n
```python
# En evaluate_model()
report = classification_report(
    y_true, y_pred, 
    target_names=class_names, 
    output_dict=True
)

# Variables extra√≠das:
f1_macro = report["macro avg"]["f1-score"]  # F1 promedio
precision = report["macro avg"]["precision"] # Precisi√≥n promedio
recall = report["macro avg"]["recall"]       # Recall promedio
```

#### Variables de Visualizaci√≥n
```python
# Para gr√°ficas de entrenamiento
acc = history.history["accuracy"]           # Accuracy por √©poca
val_acc = history.history["val_accuracy"]   # Validation accuracy
loss = history.history["loss"]              # P√©rdida de entrenamiento
val_loss = history.history["val_loss"]      # P√©rdida de validaci√≥n
```

## üîç Variables de Predicci√≥n

### Archivo: `predict.py`

#### Configuraci√≥n de Preprocesadores
```python
PREPROCESSORS = {
    "mobilenet_v2": mobilenet_v2.preprocess_input,
    "efficientnetb3": efficientnet.preprocess_input,
    "resnet50": resnet.preprocess_input,
    "resnest50": resnet.preprocess_input,  # Mismo que ResNet
    "convnext_tiny": convnext.preprocess_input,  # Preprocesador espec√≠fico ConvNeXt
}
```

#### Variables de Predicci√≥n
```python
class ModelPredictor:
    def __init__(self, model_folder):
        self.model_folder = model_folder              # Carpeta del modelo
        self.model_path = os.path.join(...)           # Ruta completa al .h5
        self.model = None                             # Modelo cargado
        self.metadata = {}                            # Metadatos del modelo
        self.class_names = []                         # Nombres de clases
        self.preprocess_fn = lambda x: x              # Funci√≥n de preprocesamiento
```

## üé® Variables de Aumentaci√≥n de Datos

### Data Augmentation en MobileNet
```python
augmentation = tf.keras.Sequential([
    layers.RandomFlip("horizontal"),    # Volteo horizontal aleatorio
    layers.RandomRotation(0.1),         # Rotaci√≥n ¬±10% (36¬∞)
    layers.RandomZoom(0.1),             # Zoom ¬±10%
])
```

**Par√°metros explicados:**
- `RandomFlip("horizontal")`: 50% probabilidad de voltear
- `RandomRotation(0.1)`: Rotar entre -36¬∞ y +36¬∞
- `RandomZoom(0.1)`: Zoom entre 90% y 110%

## üìà Variables de Callback y Monitoreo

### Callbacks Impl√≠citos en el C√≥digo
```python
# Variables de historia de entrenamiento
history.history = {
    'accuracy': [0.7, 0.8, 0.85, ...],      # Lista por √©poca
    'val_accuracy': [0.65, 0.75, 0.8, ...],
    'loss': [1.2, 0.8, 0.6, ...],
    'val_loss': [1.5, 1.0, 0.8, ...]
}
```

### Variables de Checkpoint
```python
# Timestamp para identificar experimentos
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
# Ejemplo: "20240125_143052"

# Directorio del modelo
model_dir = f"{MODEL_DIR_BASE}/{model_name}_{timestamp}"
# Ejemplo: "models/efficientnet_20240125_143052"
```

## üîß Variables de Configuraci√≥n T√©cnica

### GPU y Memoria
```python
# Configuraci√≥n impl√≠cita de TensorFlow
tf.config.experimental.set_memory_growth(gpu, True)

# Variables de batch size por GPU
batch_sizes_recommended = {
    "GPU_4GB": {"mobilenet": 32, "efficientnet": 16, "resnest": 8, "convnext": 16},
    "GPU_8GB": {"mobilenet": 64, "efficientnet": 32, "resnest": 16, "convnext": 32},
    "GPU_16GB": {"mobilenet": 128, "efficientnet": 64, "resnest": 32},
}
```

### Variables de Archivo y Guardado
```python
# Archivos generados por modelo
files_generated = {
    "model.h5": "Modelo entrenado",
    "metadata.json": "Informaci√≥n del entrenamiento",
    "evaluation_per_class.json": "M√©tricas por clase",
    "report.json": "Reporte completo de clasificaci√≥n"
}

# CSV de experimentos
experiment_columns = [
    "timestamp", "model_name", "accuracy", "val_accuracy", 
    "val_loss", "f1_score", "epochs", "class_names", "path"
]
```

## üí° Variables de Debugging

### Variables de Monitoreo
```python
# En el entrenamiento
console.log(f"[green]‚úÖ Modelo cargado: {model_name}[/green]")
console.log(f"[yellow]üìä Clases encontradas: {len(class_names)}[/yellow]")
console.log(f"[blue]üîÑ √âpocas configuradas: {epochs}[/blue]")
```

### Variables de Validaci√≥n
```python
# Validaci√≥n de estructura de datos
def validate_data_directory(data_root):
    classes = []
    for item in os.listdir(data_root):
        train_path = os.path.join(item_path, "train")
        test_path = os.path.join(item_path, "test")
        if os.path.exists(train_path) and os.path.exists(test_path):
            classes.append(item)
    
    return len(classes) > 0  # Boolean de validaci√≥n
```

## üìã Resumen de Variables Importantes

### Variables que PUEDES modificar:
```python
# En config.py
MODEL_SPECIFIC_CONFIG["mobilenet"]["learning_rate"] = 0.002  # Cambiar LR
MODEL_SPECIFIC_CONFIG["mobilenet"]["dropout_rate"] = 0.4     # M√°s regularizaci√≥n

# En models.py
"batch_size": 16,  # Reducir si tienes poca GPU RAM
"epochs": 25,      # M√°s √©pocas para mejor entrenamiento
```

### Variables que NO debes cambiar:
```python
# Arquitectura interna de los modelos
base_model.trainable = False  # Siempre False para transfer learning
AUTOTUNE = tf.data.AUTOTUNE   # Optimizaci√≥n de TensorFlow
input_shape = img_size + (3,) # Forma requerida por los modelos
```

### Variables para experimentar:
```python
# Aumentaci√≥n de datos
layers.RandomRotation(0.2),     # Probar 0.0 a 0.3
layers.RandomZoom(0.15),        # Probar 0.0 a 0.2
layers.RandomBrightness(0.1),   # Agregar nueva aumentaci√≥n

# Arquitectura
layers.Dense(128, activation='relu'),  # Probar 32, 64, 128, 256
layers.Dropout(0.5),                   # Probar 0.2, 0.3, 0.5
```

## üéØ Casos de Uso Comunes

### Para Dataset Peque√±o (<1000 im√°genes):
```python
CONFIG_SMALL = {
    "learning_rate": 0.0001,    # M√°s conservador
    "dropout_rate": 0.5,        # M√°s regularizaci√≥n
    "epochs": 25,               # M√°s √©pocas
    "batch_size": 16            # Lotes m√°s peque√±os
}
```

### Para Dataset Grande (>10000 im√°genes):
```python
CONFIG_LARGE = {
    "learning_rate": 0.001,     # M√°s agresivo
    "dropout_rate": 0.2,        # Menos regularizaci√≥n
    "epochs": 15,               # Menos √©pocas
    "batch_size": 64            # Lotes m√°s grandes
}
```

### Para GPU Limitada:
```python
CONFIG_LOW_GPU = {
    "model": "mobilenet",       # Modelo m√°s ligero
    "batch_size": 8,            # Lotes muy peque√±os
    "img_size": (224, 224)      # Resoluci√≥n est√°ndar
}
```
